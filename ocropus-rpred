#!/usr/bin/python

import random as pyrandom
import traceback
import re
from pylab import *
import os.path
import glob
import ocrolib
from ocrolib import lineest
import argparse
import cPickle
import scipy
import matplotlib
from multiprocessing import Pool
from ocrolib import edist
from collections import Counter
import ocrolib
from ocrolib import lstm

parser = argparse.ArgumentParser("apply an RNN recognizer")

# line dewarping (usually contained in model)
parser.add_argument("-e","--lineest",default=None)
parser.add_argument("-l","--height",default=-1,type=int)
parser.add_argument("-E","--nolineest",action='store_true')

# recognition
parser.add_argument("-p","--pad",default=16,type=int)
parser.add_argument('-m','--model',default=None)
parser.add_argument('-N',"--nonormalize",action="store_true")

# error measures
parser.add_argument("-r","--estrate",action="store_true",
                    help="estimate error rate only")
parser.add_argument("-c","--estconf",type=int,default=20,
                    help="estimate confusion matrix")
parser.add_argument("-C","--compare",default="nospace",
                    help="string comparison used for error rate estimate")
parser.add_argument("--context",default=0,type=int,
                    help="context for error reporting")

# debugging
parser.add_argument('-s','--show',default=-1,type=float)
parser.add_argument('-S','--save',default=None)
parser.add_argument("-q","--quiet",action="store_true")
parser.add_argument("-Q","--parallel",type=int,default=1,
                    help="number of parallel processes to use (%(default)s)")
parser.add_argument("files",nargs="+")
args = parser.parse_args()

# compute the list of files to be classified

if len(args.files)<1:
    parser.print_help()
    sys.exit(0)

inputs = ocrolib.glob_all(args.files)
if not args.quiet: print "# inputs",len(inputs)

# disable parallelism when anything is being displayed

if args.show>=0 or args.save is not None:
    args.parallel = 1

# load the network used for classification

network = ocrolib.load_object(args.model)

# get the line normalizer from the loaded network, or optionally
# let the user override it (this is not very useful)

lnorm = getattr(network,"lnorm",None)
if args.lineest is not None:
    lnorm = lineest.load_normalizer(args.lineest)

if args.height>0:
    lnorm.setHeight(args.height)

# process one file

def process1(arg):
    (trial,fname) = arg
    base,_ = ocrolib.allsplitext(fname)
    line = ocrolib.read_image_gray(fname)
    if prod(line.shape)==0: return None
    if amax(line)==amin(line): return None

    if not args.nolineest:
        assert "dew.png" not in fname,"don't dewarp dewarped images"
        temp = amax(line)-line
        temp = temp*1.0/amax(temp)
        lnorm.measure(temp)
        line = lnorm.normalize(line,cval=amax(line))
    else:
        assert "dew.png" in fname,"only apply to dewarped images"

    line = lstm.prepare_line(line,args.pad)
    pred = network.predictString(line)

    if not args.nonormalize:
        pred = ocrolib.normalize_text(pred)

    if args.estrate:
        try:
            gt = ocrolib.read_text(base+".gt.txt")
        except:
            return (0,[],0,trial,fname)
        pred0 = ocrolib.project_text(pred,args.compare)
        gt0 = ocrolib.project_text(gt,args.compare)
        if args.estconf>0:
            err,conf = edist.xlevenshtein(pred0,gt0,context=args.context)
        else:
            err = edist.xlevenshtein(pred0,gt0)
            conf = []
        if not args.quiet:
            print "%3d %3d"%(err,len(gt)),fname,":",pred
            sys.stdout.flush()
        return (err,conf,len(gt0),trial,fname)

    if not args.quiet:
        print fname,":",pred
    ocrolib.write_text(base+".txt",pred)

    if args.show>0 or args.save is not None:
        ion()
        matplotlib.rc('xtick',labelsize=7)
        matplotlib.rc('ytick',labelsize=7)
        matplotlib.rcParams.update({"font.size":7})
        if os.path.exists(base+".gt.txt"):
            transcript = ocrolib.read_text(base+".gt.txt")
            transcript = ocrolib.normalize_text(transcript)
        else:
            transcript = pred
        pred2 = network.trainString(line,transcript,update=0)
        figure("result",figsize=(1400//75,800//75),dpi=75)
        clf()
        subplot(311)
        imshow(line.T,cmap=cm.gray)
        title(transcript)
        subplot(312)
        gca().set_xticks([])
        imshow(network.outputs.T[1:],vmin=0,cmap=cm.hot)
        title(pred[:80])
        subplot(313)
        plot(network.outputs[:,0],color='yellow',linewidth=3,alpha=0.5)
        plot(network.outputs[:,1],color='green',linewidth=3,alpha=0.5)
        plot(amax(network.outputs[:,2:],axis=1),color='blue',linewidth=3,alpha=0.5)
        plot(network.aligned[:,0],color='orange',linestyle='dashed',alpha=0.7)
        plot(network.aligned[:,1],color='green',linestyle='dashed',alpha=0.5)
        plot(amax(network.aligned[:,2:],axis=1),color='blue',linestyle='dashed',alpha=0.5)
        if args.save is not None:
            draw()
            savename = args.save
            if "%" in savename: savename = savename%trial
            print "# saving",savename
            savefig(savename,bbox_inches=0)
        if trial==len(inputs)-1:
            ginput(1,99999999)
        else:
            ginput(1,args.show)
    return None

def safe_process1(arg):
    try:
        return process1(arg)
    except:
        traceback.print_exc()
        return None

if args.parallel==0:
    result = []
    for trial,fname in enumerate(inputs):
        result.append(process1((trial,fname)))
elif args.parallel==1:
    result = []
    for trial,fname in enumerate(inputs):
        result.append(safe_process1((trial,fname)))
else:
    pool = Pool(processes=args.parallel)
    result = []
    for r  in pool.imap_unordered(safe_process1,enumerate(inputs)):
        result.append(r)
        if not args.quiet and len(result)%100==0:
            sys.stderr.write("==== %d of %d\n"%(len(result),len(inputs)))

result = [x for x in result if x is not None]

confusions = []

if args.estrate:
    terr = 0
    total = 0
    for err,conf,n,trial,fname, in result:
        terr += err
        total += n
        confusions += conf
    print "%.5f"%(terr*1.0/total),terr,total,args.model
    if args.estconf>0:
        print "# top",args.estconf,"confusions (count pred gt), comparison:",args.compare
        for ((u,v),n) in Counter(confusions).most_common(args.estconf):
            print "%6d %-4s %-4s"%(n,u,v)
